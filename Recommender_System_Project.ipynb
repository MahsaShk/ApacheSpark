{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative filtering in Pyspark:\n",
    "\n",
    "spark.ml currently supports model-based collaborative filtering, in which users and products are described by a small set of latent factors that can be used to predict missing entries. spark.ml uses the alternating least squares (ALS) algorithm to learn these latent factors. ALS is a Matrix factorization approach which implements a recommendation algorithm. \n",
    "\n",
    "Your data needs to be in a specific format to work with spark.ml ALS.\n",
    "\n",
    "\n",
    "\n",
    "# Project:\n",
    "\n",
    "\n",
    "The dataset we use is the [movielens dataset](https://grouplens.org/datasets/movielens/). \n",
    "\n",
    "More dataset examples can be found at https://gist.github.com/entaroadun/1653794\n",
    "\n",
    "### Dataset detail:\n",
    "\n",
    "62,000 movies ranked by 162,000 users \n",
    "\n",
    "**'ratings.csv': **\n",
    "\n",
    "All ratings are contained in the file 'ratings.csv'. \n",
    "\n",
    "Each line of this file represents one rating of one movie by one user, and has the following format:\n",
    "\n",
    "    userId,movieId,rating,timestamp\n",
    "\n",
    "\n",
    "\n",
    "**'movies.csv': **\n",
    "\n",
    "Movie information is contained in the file 'movies.csv'. Each line of this file represents one movie, and has the following format:\n",
    "\n",
    "    movieId,title,genres\n",
    "    \n",
    "**'genome-scores.csv': **\n",
    "\n",
    "Each movie has a value for *every* tag in the genome. The tag genome encodes how strongly movies exhibit particular properties represented by tags (atmospheric, thought-provoking, realistic, etc.). The file 'genome-scores.csv' contains movie-tag relevance data in the following format:\n",
    "\n",
    "    movieId,tagId,relevance\n",
    "\n",
    "### Objective: \n",
    "\n",
    "Split to train-test then apply a **collaborative filtering algorithm** to predict the rank of test data.\n",
    "\n",
    "<!--(Content based algorithm can be applied using genome-scores.csv as features)-->\n",
    "\n",
    "<!-- explicit vs implicit collaborative filtering. Example for implicit CF see https://towardsdatascience.com/large-scale-jobs-recommendation-engine-using-implicit-data-in-pyspark-ccf8df5d910e -->\n",
    "\n",
    "### Note:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('MLlibRecommenderSys').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.csv('./ml-25m/ratings.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(userId=1, movieId=296, rating=5.0, timestamp=1147880044),\n",
       " Row(userId=1, movieId=306, rating=3.5, timestamp=1147868817)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+------------------+--------------------+\n",
      "|summary|           userId|           movieId|            rating|           timestamp|\n",
      "+-------+-----------------+------------------+------------------+--------------------+\n",
      "|  count|         25000095|          25000095|          25000095|            25000095|\n",
      "|   mean|81189.28115381162|21387.981943268616| 3.533854451353085|1.2156014431215513E9|\n",
      "| stddev|46791.71589745776| 39198.86210105973|1.0607439611423535| 2.268758080595386E8|\n",
      "|    min|                1|                 1|               0.5|           789652009|\n",
      "|    max|           162541|            209171|               5.0|          1574327703|\n",
      "+-------+-----------------+------------------+------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test split\n",
    "train, test = data.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a recommendation model instance using ALS \n",
    "als = ALS(maxIter=10, regParam=0.01, userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the model on train data\n",
    "als_model = als.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result = als_model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+----------+\n",
      "|userId|movieId|rating| timestamp|prediction|\n",
      "+------+-------+------+----------+----------+\n",
      "| 32855|    148|   4.0|1029309135|  2.993903|\n",
      "|151614|    148|   1.0| 878170956| 2.8919578|\n",
      "|131173|    148|   2.0| 842275770| 2.7699504|\n",
      "| 14831|    148|   3.0| 944148276| 3.0077996|\n",
      "| 98520|    148|   4.0|1034547175|  2.691712|\n",
      "|145182|    148|   3.0| 944952722| 2.8496423|\n",
      "| 62058|    148|   3.0| 832006144| 3.1205623|\n",
      "| 80974|    148|   3.5|1138041704| 2.7939594|\n",
      "| 29095|    148|   3.0| 944947868| 2.1337345|\n",
      "| 41703|    148|   2.0|1311022737|  3.111855|\n",
      "| 64994|    148|   1.0|1055542421| 2.4774272|\n",
      "| 84667|    148|   5.0| 832207176| 3.7432034|\n",
      "|146419|    148|   2.0| 942665835| 3.1447525|\n",
      "|132310|    148|   3.0| 836248537|  3.123418|\n",
      "| 75209|    148|   2.0|1361853682|  2.142588|\n",
      "|138552|    148|   4.0| 829756906|  3.260183|\n",
      "| 70733|    148|   1.0| 837770520| 3.5192626|\n",
      "| 88277|    148|   2.0| 839943770| 2.6598005|\n",
      "| 74794|    148|   3.0| 989050056| 2.7480023|\n",
      "| 69855|    148|   4.0| 832859557| 3.4951427|\n",
      "+------+-------+------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_eval = RegressionEvaluator(metricName='rmse', labelCol=\"rating\",predictionCol=\"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = reg_eval.evaluate(test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed RMSE  is nan\n"
     ]
    }
   ],
   "source": [
    "print(f'Computed RMSE  is {rmse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with nans:\n",
    "\n",
    "Nans at ALS test time can occur for two reasons: 1- In production, for new users or items that have no rating history; 2- When using simple random splits as in Spark’s CrossValidator or trainValidationSplit, it is very common to encounter users and/or items in the evaluation set that are not in the training set.\n",
    "\n",
    "By default, Spark assigns NaN predictions during ALSModel.transform when a user and/or item factor is not present in the model. This can be useful **in a production system**, since it indicates a new user or item, and so the system can make a decision on some fallback to use as the prediction.\n",
    "\n",
    "However, this is undesirable during cross-validation. Spark allows users to set the coldStartStrategy parameter to “drop” in ALS instance definition in order to drop any rows in the DataFrame of predictions that contain NaN values. The evaluation metric will then be computed over the non-NaN data and will be valid. \n",
    "\n",
    "Or we can simply drop Nans then compute rmse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = reg_eval.evaluate(test_result.na.drop())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed RMSE after dropping nans  is 0.8016113051718181\n"
     ]
    }
   ],
   "source": [
    "print(f'Computed RMSE after dropping nans  is {rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
