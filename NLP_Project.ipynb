{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project\n",
    "\n",
    "## Spam detection\n",
    "\n",
    "Design an SMS Spam detection using spark NLP tools and a Naive Bayes classifier.\n",
    "\n",
    "## Dataset \n",
    "\n",
    "UCI Repository SMS Spam Detection: https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection\n",
    "\n",
    "The dataset contains one set of SMS messages in English of 5,574 messages, tagged acording being ham (legitimate) or spam. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('nlpProject').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.csv(\"smsspamcollection/SMSSpamCollection\",inferSchema=True,sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+\n",
      "| _c0|                 _c1|\n",
      "+----+--------------------+\n",
      "| ham|Go until jurong p...|\n",
      "| ham|Ok lar... Joking ...|\n",
      "|spam|Free entry in 2 a...|\n",
      "| ham|U dun say so earl...|\n",
      "| ham|Nah I don't think...|\n",
      "|spam|FreeMsg Hey there...|\n",
      "| ham|Even my brother i...|\n",
      "| ham|As per your reque...|\n",
      "|spam|WINNER!! As a val...|\n",
      "|spam|Had your mobile 1...|\n",
      "| ham|I'm gonna be home...|\n",
      "|spam|SIX chances to wi...|\n",
      "|spam|URGENT! You have ...|\n",
      "| ham|I've been searchi...|\n",
      "| ham|I HAVE A DATE ON ...|\n",
      "|spam|XXXMobileMovieClu...|\n",
      "| ham|Oh k...i'm watchi...|\n",
      "| ham|Eh u remember how...|\n",
      "| ham|Fine if thats th...|\n",
      "|spam|England v Macedon...|\n",
      "+----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|             message|\n",
      "+-----+--------------------+\n",
      "|  ham|Go until jurong p...|\n",
      "|  ham|Ok lar... Joking ...|\n",
      "| spam|Free entry in 2 a...|\n",
      "|  ham|U dun say so earl...|\n",
      "|  ham|Nah I don't think...|\n",
      "| spam|FreeMsg Hey there...|\n",
      "|  ham|Even my brother i...|\n",
      "|  ham|As per your reque...|\n",
      "| spam|WINNER!! As a val...|\n",
      "| spam|Had your mobile 1...|\n",
      "|  ham|I'm gonna be home...|\n",
      "| spam|SIX chances to wi...|\n",
      "| spam|URGENT! You have ...|\n",
      "|  ham|I've been searchi...|\n",
      "|  ham|I HAVE A DATE ON ...|\n",
      "| spam|XXXMobileMovieClu...|\n",
      "|  ham|Oh k...i'm watchi...|\n",
      "|  ham|Eh u remember how...|\n",
      "|  ham|Fine if thats th...|\n",
      "| spam|England v Macedon...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = data.withColumnRenamed('_c0', 'label').withColumnRenamed('_c1', 'message')\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+\n",
      "|label|             message|               words|\n",
      "+-----+--------------------+--------------------+\n",
      "|  ham|Go until jurong p...|[go, until, juron...|\n",
      "|  ham|Ok lar... Joking ...|[ok, lar, joking,...|\n",
      "| spam|Free entry in 2 a...|[free, entry, in,...|\n",
      "|  ham|U dun say so earl...|[u, dun, say, so,...|\n",
      "|  ham|Nah I don't think...|[nah, i, don, t, ...|\n",
      "| spam|FreeMsg Hey there...|[freemsg, hey, th...|\n",
      "|  ham|Even my brother i...|[even, my, brothe...|\n",
      "|  ham|As per your reque...|[as, per, your, r...|\n",
      "| spam|WINNER!! As a val...|[winner, as, a, v...|\n",
      "| spam|Had your mobile 1...|[had, your, mobil...|\n",
      "|  ham|I'm gonna be home...|[i, m, gonna, be,...|\n",
      "| spam|SIX chances to wi...|[six, chances, to...|\n",
      "| spam|URGENT! You have ...|[urgent, you, hav...|\n",
      "|  ham|I've been searchi...|[i, ve, been, sea...|\n",
      "|  ham|I HAVE A DATE ON ...|[i, have, a, date...|\n",
      "| spam|XXXMobileMovieClu...|[xxxmobilemoviecl...|\n",
      "|  ham|Oh k...i'm watchi...|[oh, k, i, m, wat...|\n",
      "|  ham|Eh u remember how...|[eh, u, remember,...|\n",
      "|  ham|Fine if thats th...|[fine, if, that, ...|\n",
      "| spam|England v Macedon...|[england, v, mace...|\n",
      "+-----+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tokenizing on the message column\n",
    "from pyspark.ml.feature import RegexTokenizer\n",
    "regexTokenizer = RegexTokenizer(inputCol=\"message\", outputCol=\"words\", pattern=\"\\\\w+\", gaps= False)\n",
    "df_tokenized = regexTokenizer.transform(df)\n",
    "df_tokenized.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+\n",
      "|label|             message|               words|             removed|\n",
      "+-----+--------------------+--------------------+--------------------+\n",
      "|  ham|Go until jurong p...|[go, until, juron...|[go, jurong, poin...|\n",
      "|  ham|Ok lar... Joking ...|[ok, lar, joking,...|[ok, lar, joking,...|\n",
      "| spam|Free entry in 2 a...|[free, entry, in,...|[free, entry, 2, ...|\n",
      "|  ham|U dun say so earl...|[u, dun, say, so,...|[u, dun, say, ear...|\n",
      "|  ham|Nah I don't think...|[nah, i, don, t, ...|[nah, think, goes...|\n",
      "| spam|FreeMsg Hey there...|[freemsg, hey, th...|[freemsg, hey, da...|\n",
      "|  ham|Even my brother i...|[even, my, brothe...|[even, brother, l...|\n",
      "|  ham|As per your reque...|[as, per, your, r...|[per, request, me...|\n",
      "| spam|WINNER!! As a val...|[winner, as, a, v...|[winner, valued, ...|\n",
      "| spam|Had your mobile 1...|[had, your, mobil...|[mobile, 11, mont...|\n",
      "|  ham|I'm gonna be home...|[i, m, gonna, be,...|[m, gonna, home, ...|\n",
      "| spam|SIX chances to wi...|[six, chances, to...|[six, chances, wi...|\n",
      "| spam|URGENT! You have ...|[urgent, you, hav...|[urgent, won, 1, ...|\n",
      "|  ham|I've been searchi...|[i, ve, been, sea...|[ve, searching, r...|\n",
      "|  ham|I HAVE A DATE ON ...|[i, have, a, date...|      [date, sunday]|\n",
      "| spam|XXXMobileMovieClu...|[xxxmobilemoviecl...|[xxxmobilemoviecl...|\n",
      "|  ham|Oh k...i'm watchi...|[oh, k, i, m, wat...|[oh, k, m, watching]|\n",
      "|  ham|Eh u remember how...|[eh, u, remember,...|[eh, u, remember,...|\n",
      "|  ham|Fine if thats th...|[fine, if, that, ...|[fine, way, u, fe...|\n",
      "| spam|England v Macedon...|[england, v, mace...|[england, v, mace...|\n",
      "+-----+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#StopWord removing on message column\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "remover = StopWordsRemover(inputCol ='words', outputCol ='removed')\n",
    "df_tokenized_stw = remover.transform(df_tokenized)\n",
    "df_tokenized_stw.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get TF-IDF feature vector\n",
    "from pyspark.ml.feature import HashingTF, IDF\n",
    "# 1st get TF (term frequency) \n",
    "hashing_tf = HashingTF(inputCol='words', outputCol='rawFeatures') \n",
    "featurized_data = hashing_tf.transform(df_tokenized_stw)\n",
    "\n",
    "# 1st get IDF\n",
    "idf = IDF(inputCol='rawFeatures', outputCol='features')\n",
    "idf_model = idf.fit(featurized_data)\n",
    "rescaled_data = idf_model.transform(featurized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|label|             message|               words|             removed|         rawFeatures|            features|\n",
      "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|  ham|Go until jurong p...|[go, until, juron...|[go, jurong, poin...|(262144,[38555,52...|(262144,[38555,52...|\n",
      "|  ham|Ok lar... Joking ...|[ok, lar, joking,...|[ok, lar, joking,...|(262144,[16877,51...|(262144,[16877,51...|\n",
      "| spam|Free entry in 2 a...|[free, entry, in,...|[free, entry, 2, ...|(262144,[12250,12...|(262144,[12250,12...|\n",
      "|  ham|U dun say so earl...|[u, dun, say, so,...|[u, dun, say, ear...|(262144,[2306,517...|(262144,[2306,517...|\n",
      "|  ham|Nah I don't think...|[nah, i, don, t, ...|[nah, think, goes...|(262144,[19036,25...|(262144,[19036,25...|\n",
      "| spam|FreeMsg Hey there...|[freemsg, hey, th...|[freemsg, hey, da...|(262144,[19036,19...|(262144,[19036,19...|\n",
      "|  ham|Even my brother i...|[even, my, brothe...|[even, brother, l...|(262144,[27576,48...|(262144,[27576,48...|\n",
      "|  ham|As per your reque...|[as, per, your, r...|[per, request, me...|(262144,[12650,27...|(262144,[12650,27...|\n",
      "| spam|WINNER!! As a val...|[winner, as, a, v...|[winner, valued, ...|(262144,[23209,27...|(262144,[23209,27...|\n",
      "| spam|Had your mobile 1...|[had, your, mobil...|[mobile, 11, mont...|(262144,[1546,219...|(262144,[1546,219...|\n",
      "|  ham|I'm gonna be home...|[i, m, gonna, be,...|[m, gonna, home, ...|(262144,[12716,17...|(262144,[12716,17...|\n",
      "| spam|SIX chances to wi...|[six, chances, to...|[six, chances, wi...|(262144,[7415,256...|(262144,[7415,256...|\n",
      "| spam|URGENT! You have ...|[urgent, you, hav...|[urgent, won, 1, ...|(262144,[4629,232...|(262144,[4629,232...|\n",
      "|  ham|I've been searchi...|[i, ve, been, sea...|[ve, searching, r...|(262144,[15585,19...|(262144,[15585,19...|\n",
      "|  ham|I HAVE A DATE ON ...|[i, have, a, date...|      [date, sunday]|(262144,[19036,39...|(262144,[19036,39...|\n",
      "| spam|XXXMobileMovieClu...|[xxxmobilemoviecl...|[xxxmobilemoviecl...|(262144,[26364,27...|(262144,[26364,27...|\n",
      "|  ham|Oh k...i'm watchi...|[oh, k, i, m, wat...|[oh, k, m, watching]|(262144,[18184,19...|(262144,[18184,19...|\n",
      "|  ham|Eh u remember how...|[eh, u, remember,...|[eh, u, remember,...|(262144,[12524,19...|(262144,[12524,19...|\n",
      "|  ham|Fine if thats th...|[fine, if, that, ...|[fine, way, u, fe...|(262144,[48448,51...|(262144,[48448,51...|\n",
      "| spam|England v Macedon...|[england, v, mace...|[england, v, mace...|(262144,[27576,30...|(262144,[27576,30...|\n",
      "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rescaled_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
