{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join two DataFrames in Pyspark:\n",
    "\n",
    "We use the function **join()** to join the two DataFrames dfL and dfR:\n",
    "\n",
    "dfL.join(dfR, on=None, how=None)\n",
    "\n",
    "**on**: a string for the join column name, a list of column names, or a join expression (column)\n",
    "\n",
    "**how**: a string. Default: 'inner'. Must be one of: inner, cross, outer, full, fullouter, full_outer, left, leftouter, left_outer, right, rightouter, right_outer, semi, leftsemi, left_semi, anti, leftanti and left_anti.\n",
    "(Note:  some of the above join types do the same thing!)\n",
    "\n",
    "\n",
    "## The join types can be divided into 7 categories: \n",
    "\n",
    "1- inner\n",
    "\n",
    "2- fullouter / full_outer/ outer / full\n",
    "\n",
    "3- leftouter/ left_outer / left\n",
    "\n",
    "4- rightouter /  right_outer / right\n",
    "\n",
    "5- leftsemi/ left_semi/ semi\n",
    "\n",
    "6- leftanti/ left_anti/ anti\n",
    "\n",
    "7- cross"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## As an example we want to join two DataFrames of dfL and dfR: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('dfJoin').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfL = spark.createDataFrame([(100, \"Andy\", \"22\"),(200, \"Bob\", \"23\"), (300, \"Alice\", \"23\")],[\"id\", \"name\", \"age\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+---+\n",
      "| id| name|age|\n",
      "+---+-----+---+\n",
      "|100| Andy| 22|\n",
      "|200|  Bob| 23|\n",
      "|300|Alice| 23|\n",
      "+---+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfL.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfR = spark.createDataFrame([(100, \"Andy\", \"B\"),(400, \"David\", \"C\"), (500, \"Sarah\",\"A\")],[\"id\", \"name\",\"GPA\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+---+\n",
      "| id| name|GPA|\n",
      "+---+-----+---+\n",
      "|100| Andy|  B|\n",
      "|400|David|  C|\n",
      "|500|Sarah|  A|\n",
      "+---+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfR.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1- Inner Join\n",
    "Keep only records whose key exists in both DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+---+---+\n",
      "| id|name|age|GPA|\n",
      "+---+----+---+---+\n",
      "|100|Andy| 22|  B|\n",
      "+---+----+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_inJ = dfL.join(dfR, on=['id','name'], how='inner')\n",
    "df_inJ.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2- Outter join \n",
    "Keep records from both DataFrames, inserting **null** in either DataFrames when there is no matching record.\n",
    "\n",
    "The parameter *how* can be set as *fullouter/full_outer/outer/full*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----+----+\n",
      "| id| name| age| GPA|\n",
      "+---+-----+----+----+\n",
      "|500|Sarah|null|   A|\n",
      "|400|David|null|   C|\n",
      "|100| Andy|  22|   B|\n",
      "|200|  Bob|  23|null|\n",
      "|300|Alice|  23|null|\n",
      "+---+-----+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_outJ = dfL.join(dfR, on=['id','name'], how='outer')\n",
    "df_outJ.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3- Left outter join \n",
    "Keep all records on the left side, keep null in right side where there are no match keys.\n",
    "\n",
    "The parameter *how* can be set as *leftouter/left_outer/left*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+---+----+\n",
      "| id| name|age| GPA|\n",
      "+---+-----+---+----+\n",
      "|100| Andy| 22|   B|\n",
      "|200|  Bob| 23|null|\n",
      "|300|Alice| 23|null|\n",
      "+---+-----+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_LoutJ = dfL.join(dfR, on=['id','name'], how='leftouter')\n",
    "df_LoutJ.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4- Right outter join \n",
    "Keep all records on the right side, keep null in left side where there are no match keys.\n",
    "\n",
    "The parameter *how* can be set as *rightouter/right_outer/right*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----+---+\n",
      "| id| name| age|GPA|\n",
      "+---+-----+----+---+\n",
      "|500|Sarah|null|  A|\n",
      "|400|David|null|  C|\n",
      "|100| Andy|  22|  B|\n",
      "+---+-----+----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_RoutJ = dfL.join(dfR, on=['id','name'], how='rightouter')\n",
    "df_RoutJ.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5- Left semi join\n",
    "Keep only the **left table** (donâ€™t show the right table), where **the join condition is met**. This is a useful filtering mechanism.\n",
    "\n",
    "The parameter *how* can be set as *leftsemi/left_semi/semi*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+---+\n",
      "| id|name|age|\n",
      "+---+----+---+\n",
      "|100|Andy| 22|\n",
      "+---+----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_Lsemi = dfL.join(dfR, on=['id','name'], how='semi')\n",
    "df_Lsemi.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6- Left anti join\n",
    "This is the **complement of the left semi join**. In this case you return only the left table where the join **condition is NOT met**.\n",
    "\n",
    "The parameter *how* can be set as *leftanti/left_anti/anti*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+---+\n",
      "| id| name|age|\n",
      "+---+-----+---+\n",
      "|200|  Bob| 23|\n",
      "|300|Alice| 23|\n",
      "+---+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_Lanti = dfL.join(dfR, on=['id','name'], how='anti')\n",
    "df_Lanti.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7- Cross join\n",
    "\n",
    "Join each row on the left with every row on the right. Each DataFrame has 3 rows, so the resulting DataFrame will have 3*3 = 9 rows.\n",
    "\n",
    "This join can result in large output so use it cautiously!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+---+---+-----+---+\n",
      "| id| name|age| id| name|GPA|\n",
      "+---+-----+---+---+-----+---+\n",
      "|100| Andy| 22|100| Andy|  B|\n",
      "|100| Andy| 22|400|David|  C|\n",
      "|100| Andy| 22|500|Sarah|  A|\n",
      "|200|  Bob| 23|100| Andy|  B|\n",
      "|200|  Bob| 23|400|David|  C|\n",
      "|200|  Bob| 23|500|Sarah|  A|\n",
      "|300|Alice| 23|100| Andy|  B|\n",
      "|300|Alice| 23|400|David|  C|\n",
      "|300|Alice| 23|500|Sarah|  A|\n",
      "+---+-----+---+---+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_cross = dfL.crossJoin(dfR)\n",
    "df_cross.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using join expression:\n",
    "\n",
    "We can define join Conditions as bellow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+---+---+----+---+\n",
      "| id|name|age| id|name|GPA|\n",
      "+---+----+---+---+----+---+\n",
      "|100|Andy| 22|100|Andy|  B|\n",
      "+---+----+---+---+----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joinExpression = [dfL.name == dfR.name , dfL.id == dfR.id]\n",
    "\n",
    "df_inJ = dfL.join(dfR, joinExpression, how='inner')\n",
    "df_inJ.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
